{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining an evaluation strategies for an AI application\n",
    "\n",
    "Often times, we want to evaluate an AI application based on multiple metrics. We can create as many metrics as we want, and then define an evaluation strategy that aggregates them.\n",
    "\n",
    "In this tutorial, we will learn how to create an multi-dimensional error detection strategy utilizing different judges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application\n",
    "\n",
    "We want to evaluate an AI application that helps journalists generate articles.\n",
    "\n",
    "The user provides instructions for the article, that can include context, and the application generates an article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data\n",
    "\n",
    "For illustration purposes, we will use only 2 articles synthetically generated by an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context = \"\"\"GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models\n",
    "Tyna Eloundou, Sam Manning, Pamela Mishkin, Daniel Rock\n",
    "We investigate the potential implications of large language models (LLMs), such as Generative Pre-trained Transformers (GPTs), on the U.S. labor market, focusing on the increased capabilities arising from LLM-powered software compared to LLMs on their own. Using a new rubric, we assess occupations based on their alignment with LLM capabilities, integrating both human expertise and GPT-4 classifications. Our findings reveal that around 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs, while approximately 19% of workers may see at least 50% of their tasks impacted. We do not make predictions about the development or adoption timeline of such LLMs. The projected effects span all wage levels, with higher-income jobs potentially facing greater exposure to LLM capabilities and LLM-powered software. Significantly, these impacts are not restricted to industries with higher recent productivity growth. Our analysis suggests that, with access to an LLM, about 15% of all worker tasks in the US could be completed significantly faster at the same level of quality. When incorporating software and tooling built on top of LLMs, this share increases to between 47 and 56% of all tasks. This finding implies that LLM-powered software will have a substantial effect on scaling the economic impacts of the underlying models. We conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications.\n",
    "\n",
    "Our study is motivated less by the progress of these models alone though, and more by the breadth,\n",
    "scale, and capabilities we’ve seen in the complementary technologies developed around them. The role of\n",
    "complementary technologies remains to be seen, but maximizing the impact of LLMs appears contingent\n",
    "on integrating them with larger systems (Bresnahan, 2019; Agrawal et al., 2021). While the focus of our\n",
    "discussion is primarily on the generative capabilities of LLMs, it is important to note that these models can\n",
    "also be utilized for various tasks beyond text generation. For example, embeddings from LLMs can be used\n",
    "for custom search applications, and LLMs can perform tasks such as summarization and classification where\n",
    "the context may be largely contained in the prompt.\n",
    "To complement predictions of technology’s impacts on work and provide a framework for understanding\n",
    "the evolving landscape of language models and their associated technologies, we propose a new rubric\n",
    "for assessing LLM capabilities and their potential effects on jobs. This rubric (A.1) measures the overall\n",
    "exposure of tasks to LLMs, following the spirit of prior work on quantifying exposure to machine learning\n",
    "(Brynjolfsson et al., 2018; Felten et al., 2018; Webb, 2020). We define exposure as a proxy for potential\n",
    "economic impact without distinguishing between labor-augmenting or labor-displacing effects. We employ\n",
    "human annotators and GPT-4 itself as a classifier to apply this rubric to occupational data in the U.S. economy,\n",
    "primarily sourced from the O*NET database.1 2\n",
    "To construct our primary exposure dataset, we collected both human annotations and GPT-4 classifications,\n",
    "using a prompt tuned for agreement with a sample of labels from the authors. We observe similar agreement\n",
    "\n",
    "In conclusion, this study offers an examination of the potential impact of LLMs on various occupations and\n",
    "industries within the U.S. economy. By applying a new rubric for understanding LLM capabilities and their\n",
    "potential effects on jobs, we have observed that most occupations exhibit some degree of exposure to LLMs,\n",
    "with higher-wage occupations generally presenting more tasks with high exposure. Our analysis indicates that\n",
    "approximately 19% of jobs have at least 50% of their tasks exposed to LLMs when considering both current\n",
    "model capabilities and anticipated LLM-powered software.\n",
    "Our research aims to highlight the general-purpose potential of LLMs and their possible implications for\n",
    "US workers. Previous literature demonstrates the impressive improvements of LLMs to date (see 2.1). Our\n",
    "findings confirm the hypothesis that these technologies can have pervasive impacts across a wide swath of\n",
    "occupations in the US, and that additional advancements supported by LLMs, mainly through software and\n",
    "digital tools, can have significant effects on a range of economic activities. However, while the technical\n",
    "capacity for LLMs to make human labor more efficient appears evident, it is important to recognize that social,\n",
    "economic, regulatory, and other factors will influence actual labor productivity outcomes. As capabilities\n",
    "continue to evolve, the impact of LLMs on the economy will likely persist and increase, posing challenges for\n",
    "policymakers in predicting and regulating their trajectory.\n",
    "Further research is necessary to explore the broader implications of LLM advancements, including\n",
    "their potential to augment or displace human labor, their impact on job quality, impacts on inequality, skill\n",
    "development, and numerous other outcomes. By seeking to understand the capabilities and potential effect\"\"\"\n",
    "\n",
    "user_instructions = \"\"\"AI is here to stay and we need to understand how AI is gonna impact the job market.\n",
    "\n",
    "Use the information in the context to write a comprehensive article.\n",
    "\n",
    "Please provide clear paragraph separation.\"\"\"\n",
    "\n",
    "article_1 = \"\"\"# AI's Impact on the Job Market: A Comprehensive Look at Large Language Models\n",
    "\n",
    "Artificial Intelligence (AI) is no longer a futuristic concept; it's here, and its impact on the job market is becoming increasingly apparent. A recent study by researchers Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock sheds light on how large language models (LLMs), such as GPT-4, could potentially reshape the U.S. labor landscape.\n",
    "\n",
    "## The Widespread Impact of AI on Jobs\n",
    "\n",
    "The study reveals a startling statistic: approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of LLMs. Even more striking, about 19% of workers may see at least 50% of their tasks impacted. This suggests that AI's influence on the job market is not limited to a few sectors but could have far-reaching consequences across various industries.\n",
    "\n",
    "## Higher-Income Jobs at Greater Risk\n",
    "\n",
    "Contrary to popular belief, it's not just low-wage jobs that are vulnerable to AI disruption. The research indicates that higher-income jobs potentially face greater exposure to LLM capabilities and LLM-powered software. This finding challenges the notion that AI will primarily affect routine, low-skill tasks and suggests a more complex transformation of the labor market.\n",
    "\n",
    "## The Power of LLM-Powered Software\n",
    "\n",
    "While LLMs alone are impressive, the study emphasizes the potential of software and tools built on top of these models. With access to an LLM, about 15% of all worker tasks in the U.S. could be completed significantly faster at the same level of quality. However, when incorporating LLM-powered software, this share increases dramatically to between 47 and 56% of all tasks. This highlights the importance of considering not just the AI models themselves, but also the ecosystem of tools and applications that leverage their capabilities.\n",
    "\n",
    "## AI as a General-Purpose Technology\n",
    "\n",
    "The researchers conclude that LLMs such as GPTs exhibit traits of general-purpose technologies, indicating that they could have considerable economic, social, and policy implications. This classification puts AI in the same category as other transformative technologies like electricity or the internet, suggesting its potential to reshape multiple sectors of the economy.\n",
    "\n",
    "## The Need for Further Research and Policy Considerations\n",
    "\n",
    "While the study provides valuable insights into AI's potential impact on the job market, it also highlights the need for further research. The authors stress the importance of exploring the broader implications of LLM advancements, including their potential to augment or displace human labor, impact job quality, influence inequality, and affect skill development.\n",
    "\n",
    "As AI continues to evolve and integrate into various aspects of work, policymakers face the challenge of predicting and regulating its trajectory. The pervasive nature of AI's potential impact underscores the need for proactive policies that can help workers and industries adapt to this technological shift.\n",
    "\n",
    "In conclusion, AI is indeed here to stay, and its impact on the job market is likely to be profound and wide-ranging. As we navigate this new landscape, it's crucial for workers, employers, and policymakers to stay informed and adaptable, ready to harness the potential of AI while mitigating its potential disruptions to the workforce.\"\"\"\n",
    "article_2 =\"\"\"# Artificial Intelligence Might Change Everything About Jobs, New Study Claims\n",
    "\n",
    "In a world where technology seems to be taking over everything, a new study has come out that's got everyone talking. It's all about how artificial intelligence, or AI for short, could shake up the job market in a big way. The study, done by some researchers with really long names, looks at something called \"large language models\" or LLMs. These are like super smart computer programs that can understand and write text, kind of like a robot writer.\n",
    "\n",
    "So, these researchers say that these LLMs could affect a whopping 80% of workers in the United States. That's a lot of people! They think that for most of these workers, at least 10% of what they do at work could be changed by AI. And for some people, it could be even more - like half of their job tasks! Can you imagine that? It's like having a robot colleague that can do half your work.\n",
    "\n",
    "But here's the really weird part - it's not just the simple jobs that might be affected. The study says that people with high-paying jobs might actually be more at risk. That's pretty surprising, right? You'd think it would be the other way around. I guess even the bosses aren't safe from the robot invasion!\n",
    "\n",
    "The researchers also talked about something called \"LLM-powered software.\" Basically, that's when you take these smart AI programs and use them to make other computer programs. They say this could make an even bigger difference. With this kind of software, almost half of all the tasks people do at work could be done faster or better. That's a lot of change!\n",
    "\n",
    "Now, the study doesn't say exactly when all this is going to happen. It's not like we're going to wake up tomorrow and find robots sitting at our desks. But it does seem like it could be a big deal in the future. The researchers think AI could be as important as electricity was when it was invented. Remember learning about that in history class? It changed everything!\n",
    "\n",
    "Of course, not everyone agrees about how big a deal this is going to be. Some people think the researchers are exaggerating, and that AI won't really change that much. Others are worried that it could lead to a lot of people losing their jobs. It's hard to know who's right.\n",
    "\n",
    "The study also talks about how AI might affect different industries. But to be honest, it gets pretty complicated and boring at that point. There's a lot of technical stuff about \"productivity growth\" and \"economic implications\" that I didn't really understand. I guess that's why these researchers get paid the big bucks!\n",
    "\n",
    "In the end, the main takeaway seems to be that AI is coming, and it's going to change things. Whether that's good or bad probably depends on your job and how well you can adapt to working with robot helpers. Maybe it's time to start being extra nice to your computer, just in case!\n",
    "\n",
    "The researchers say we need to do more studies to really understand what's going to happen. They want to look at things like how AI might make some jobs better or worse, and how it might affect inequality. That sounds like a lot more work for them!\n",
    "\n",
    "So, there you have it. AI is coming for our jobs, maybe. Or maybe not. It's all very exciting and confusing at the same time. I guess we'll just have to wait and see what happens. In the meantime, maybe we should all start learning how to program these AI things. You know, just in case.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation criteria and rubrics\n",
    "\n",
    "We want to evaluate the articles based on the following criteria:\n",
    "\n",
    "| Evaluation | Explanation |\n",
    "|------------|-------------|\n",
    "| Completeness | Does the article provide comprehensive coverage of the topics and information the instructions provided, addressing all relevant aspects and key points? |\n",
    "| Clarity | Is the article written in a clear, concise, and easily understandable manner? |\n",
    "| Source Attribution | Does the article properly attribute information to reliable sources provided in the information and the instructions? |\n",
    "| Objectivity | Does the article present information in an unbiased manner, considering multiple perspectives? |\n",
    "\n",
    "These metric are a measure of the quality of the generated article.\n",
    "\n",
    "Since we want to create a multi-dimensional error detection system, we are going to create rubrics in a Pass / Fail scoring scale.\n",
    "\n",
    "Let's create the custom rubrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_judge.metrics import CustomMetric, RubricItem\n",
    "\n",
    "completeness_criteria = \"Evaluate the extent to which the article provides comprehensive coverage of all topics, key points, and information specified in the instructions, ensuring that no relevant aspects are omitted or inadequately addressed.\"\n",
    "completeness_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article fails to provide comprehensive coverage of the required topics, key points, and information specified in the instructions. It omits crucial information and has significant gaps in addressing relevant aspects.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article offers comprehensive coverage of all required topics, key points, and information specified in the instructions. It thoroughly addresses all relevant aspects, providing in-depth information and leaving no significant gaps in coverage.\"\n",
    "    )\n",
    "]\n",
    "COMPLETENESS_METRIC = CustomMetric(\n",
    "    name=\"completeness\",\n",
    "    criteria=completeness_criteria,\n",
    "    rubric=completeness_rubric\n",
    ")\n",
    "\n",
    "clarity_criteria = \"Does the article's writing quality in terms of clarity, conciseness, and ease of understanding communicate effectively the information to the reader?\"\n",
    "clarity_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article's writing quality is poor to moderate in terms of clarity, conciseness, and ease of understanding. It may have confusing sentence structures, inappropriate vocabulary, lack of organization, or instances of unnecessary verbosity. The writing does not effectively communicate the information to the reader, making it difficult to comprehend the content without significant effort.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article's writing quality is high in terms of clarity, conciseness, and ease of understanding. It features well-constructed sentences, appropriate vocabulary, logical organization, and efficient conveyance of information. The writing effectively communicates the information to the reader, allowing for easy comprehension and a smooth reading experience.\"\n",
    "    )\n",
    "]\n",
    "CLARITY_METRIC = CustomMetric(\n",
    "    name=\"clarity\",\n",
    "    criteria=clarity_criteria,\n",
    "    rubric=clarity_rubric\n",
    ")\n",
    "\n",
    "source_attribution_criteria = \"Does the article accurately and comprehensively attribute information to reliable sources, ensuring that these sources align with those provided in the information and instructions?\"\n",
    "source_attribution_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article fails to accurately and comprehensively attribute information to reliable sources. There are significant gaps or inaccuracies in attribution, and many sources either do not align with those provided in the instructions or are unreliable. Attribution practices are inconsistent or inadequate, with key information often lacking proper sourcing.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article accurately and comprehensively attributes information to reliable sources that align with those provided in the information and instructions. Attribution practices are consistently followed throughout the article, with all key information properly sourced and credited. The sourcing is appropriate and demonstrates excellent adherence to attribution standards.\"\n",
    "    )\n",
    "]\n",
    "SOURCE_ATTRIBUTION_METRIC = CustomMetric(\n",
    "    name=\"source_attribution\",\n",
    "    criteria=source_attribution_criteria,\n",
    "    rubric=source_attribution_rubric\n",
    ")\n",
    "\n",
    "objectivity_criteria = \"Evaluate whether the article presents information in an unbiased manner by incorporating multiple perspectives fairly and avoiding partisan or one-sided reporting.\"\n",
    "objectivity_rubric = [\n",
    "    RubricItem(\n",
    "        score=0,\n",
    "        description=\"The article shows significant bias in its reporting. It either presents only one perspective or heavily favors a particular viewpoint. Alternative views are absent, minimized, or unfairly represented. The language used may be loaded or emotionally charged, and sources may be limited to those supporting a single perspective. The overall presentation lacks journalistic objectivity and balance.\"\n",
    "    ),\n",
    "    RubricItem(\n",
    "        score=1,\n",
    "        description=\"The article demonstrates a commitment to unbiased reporting. It presents multiple perspectives on the topic, giving fair representation to different viewpoints. The language used is neutral and objective, avoiding loaded terms or emotional rhetoric. The article uses a diverse range of credible sources to support various perspectives. While minor imperfections may exist, the overall presentation maintains journalistic integrity, balance, and objectivity.\"\n",
    "    )\n",
    "]\n",
    "OBJECTIVITY_METRIC = CustomMetric(\n",
    "    name=\"objectivity\",\n",
    "    criteria=objectivity_criteria,\n",
    "    rubric=objectivity_rubric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom FlowJudge's\n",
    "\n",
    "We can now easily create a model and the different judges to build our multi-dimensional error detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_judge.models.model_factory import ModelFactory\n",
    "from flow_judge.flow_judge import EvalInput, FlowJudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-17 15:32:08 awq_marlin.py:89] The model is convertible to awq_marlin during runtime. Using awq_marlin kernel.\n",
      "WARNING 09-17 15:32:08 config.py:378] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 09-17 15:32:08 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='flowaicom/Flow-Judge-v0.1-AWQ', speculative_config=None, tokenizer='flowaicom/Flow-Judge-v0.1-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq_marlin, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=flowaicom/Flow-Judge-v0.1-AWQ, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=False)\n",
      "INFO 09-17 15:32:08 model_runner.py:915] Starting to load model flowaicom/Flow-Judge-v0.1-AWQ...\n",
      "INFO 09-17 15:32:09 weight_utils.py:236] Using model weights format ['*.safetensors']\n",
      "INFO 09-17 15:32:09 weight_utils.py:280] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89aa80168e8477ebe09ca6aa64db993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-17 15:32:10 model_runner.py:926] Loading model weights took 2.1861 GB\n",
      "INFO 09-17 15:32:11 gpu_executor.py:122] # GPU blocks: 3083, # CPU blocks: 682\n"
     ]
    }
   ],
   "source": [
    "# Create a model using ModelFactory\n",
    "model = ModelFactory.create_model(\"Flow-Judge-v0.1-AWQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create judges\n",
    "completeness_judge = FlowJudge(\n",
    "    metric=COMPLETENESS_METRIC,\n",
    "    model=model\n",
    ")\n",
    "clarity_judge = FlowJudge(\n",
    "    metric=CLARITY_METRIC,\n",
    "    model=model\n",
    ")\n",
    "source_attribution_judge = FlowJudge(\n",
    "    metric=SOURCE_ATTRIBUTION_METRIC,\n",
    "    model=model\n",
    ")\n",
    "objectivity_judge = FlowJudge(\n",
    "    metric=OBJECTIVITY_METRIC,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of inputs and outputs\n",
    "inputs_batch = [\n",
    "    [\n",
    "        {\"user_instructions\": user_instructions},\n",
    "        {\"context\": context}\n",
    "    ],\n",
    "    [\n",
    "        {\"user_instructions\": user_instructions},\n",
    "        {\"context\": context}\n",
    "    ]\n",
    "]\n",
    "outputs_batch = [article_1, article_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [00:10<00:00,  5.16s/it, est. speed input: 538.42 toks/s, output: 62.14 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it, est. speed input: 706.96 toks/s, output: 84.22 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it, est. speed input: 1326.56 toks/s, output: 77.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 2/2 [00:07<00:00,  3.86s/it, est. speed input: 739.97 toks/s, output: 81.70 toks/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of EvalInput\n",
    "eval_inputs_batch = [EvalInput(inputs=inputs, output=output) for inputs, output in zip(inputs_batch, outputs_batch)]\n",
    "\n",
    "# Run batch evaluations for all judges\n",
    "completeness_results = completeness_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "clarity_results = clarity_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "source_attribution_results = source_attribution_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "objectivity_results = objectivity_judge.batch_evaluate(eval_inputs_batch, save_results=False)\n",
    "\n",
    "# Combine results\n",
    "all_results = {\n",
    "    \"completeness\": completeness_results,\n",
    "    \"clarity\": clarity_results,\n",
    "    \"source_attribution\": source_attribution_results,\n",
    "    \"objectivity\": objectivity_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Article 1\n",
       "\n",
       "| Metric | Score |\n",
       "|--------|-------|\n",
       "| completeness | 1 |\n",
       "| clarity | 1 |\n",
       "| source_attribution | 1 |\n",
       "| objectivity | 1 |\n",
       "\n",
       "### Feedback\n",
       "\n",
       "**Completeness**: The article provides comprehensive coverage of the key points and information specified in the instructions. It addresses the potential impact of large language models (LLMs) on the U.S. job market, including statistics on task exposure and the broader implications for various occupations and industries. The article also discusses the potential for LLM-powered software to significantly increase productivity, the impact on higher-income jobs, and the need for further research and policy considerations. Additionally, it highlights the general-purpose nature of LLMs and their potential as transformative technologies. The article concludes with a call for proactive policies and adaptability in the face of AI's impact on the workforce. Overall, the article thoroughly addresses all relevant aspects and provides in-depth information without significant gaps in coverage.\n",
       "\n",
       "**Clarity**: The article's writing quality is high in terms of clarity, conciseness, and ease of understanding. The content is well-structured, with clear paragraph separation and logical flow. The vocabulary used is appropriate and precise, effectively conveying complex information about AI's impact on the job market.\n",
       "\n",
       "The article begins with a strong introduction that sets the context and introduces the main topic. Each subsequent section is well-organized, focusing on specific aspects of AI's impact on jobs. The use of headings and subheadings helps to guide the reader through the content, making it easy to follow the arguments and findings presented.\n",
       "\n",
       "The writing is concise yet comprehensive, avoiding unnecessary verbosity while still providing a thorough overview of the research findings. Complex ideas are explained clearly, such as the distinction between labor-augmenting and labor-displacing effects of AI.\n",
       "\n",
       "The conclusion effectively summarizes the key points and highlights the broader implications of the research, providing a clear takeaway for the reader.\n",
       "\n",
       "Overall, the writing style is engaging and accessible, allowing readers with varying levels of familiarity with AI and economics to understand the main points and implications of the study. The article effectively communicates the information, making it easy for readers to comprehend the potential impact of AI on the job market.\n",
       "\n",
       "**Source_attribution**: The article accurately and comprehensively attributes information to reliable sources that align with those provided in the instructions. The researchers Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock are correctly credited for their study on the impact of large language models (LLMs) on the job market. The article also references the use of GPT-4 as a classifier, which aligns with the context provided. The sourcing is appropriate and demonstrates excellent adherence to attribution standards. All key information is properly sourced and credited, ensuring the article's credibility and reliability.\n",
       "\n",
       "**Objectivity**: The article presents information in an unbiased manner by incorporating multiple perspectives fairly and avoiding partisan or one-sided reporting. It discusses the potential impact of large language models (LLMs) on the job market, highlighting both positive and negative aspects. The article acknowledges that while LLMs can increase efficiency, they also pose challenges to labor productivity outcomes. It also mentions the need for further research to explore broader implications, such as job quality, inequality, and skill development. The language used is neutral and objective, avoiding loaded terms or emotional rhetoric. The article does not heavily favor a particular viewpoint and presents a balanced view of the topic.\n",
       "\n",
       "However, the article could have included more diverse perspectives, such as those of workers, employers, or policymakers, to further enhance its objectivity. Additionally, while it mentions the need for further research, it could have provided more specific examples or studies to support this claim.\n",
       "\n",
       "Overall, the article demonstrates a commitment to unbiased reporting and maintains journalistic integrity and balance, but there is room for improvement in terms of including a wider range of perspectives and sources.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Article 2\n",
       "\n",
       "| Metric | Score |\n",
       "|--------|-------|\n",
       "| completeness | 0 |\n",
       "| clarity | 0 |\n",
       "| source_attribution | 0 |\n",
       "| objectivity | 0 |\n",
       "\n",
       "### Feedback\n",
       "\n",
       "**Completeness**: The article provides a general overview of the potential impact of large language models (LLMs) on the job market, but it falls short of comprehensive coverage of all the required topics and key points specified in the instructions. While it touches on some important aspects, there are significant gaps and omissions that prevent it from fully addressing the scope of the task.\n",
       "\n",
       "The article covers some key points such as the potential for LLMs to affect 80% of U.S. workers and the possibility of half of job tasks being impacted. It also mentions the surprising finding that high-wage jobs might be more at risk and the concept of LLM-powered software. However, it fails to provide a thorough analysis of the implications for different industries, the potential for job creation, and the broader economic impacts.\n",
       "\n",
       "The article lacks depth in several areas:\n",
       "1. It doesn't adequately address the potential for LLMs to augment rather than replace human labor.\n",
       "2. There's no discussion on how these technologies might impact job quality or skill requirements.\n",
       "3. The potential for LLMs to create new job categories or industries is not explored.\n",
       "4. The article doesn't address the potential for LLMs to improve productivity in existing jobs.\n",
       "5. There's no discussion on the potential for LLMs to enable new forms of work or business models.\n",
       "\n",
       "Furthermore, the article oversimplifies some complex concepts and fails to provide in-depth analysis on several points mentioned in the original context, such as the specific rubric used for assessing LLM capabilities and their potential effects on jobs.\n",
       "\n",
       "While the article does provide a general overview that might be accessible to a broad audience, it lacks the depth and comprehensiveness required to fully address the task as specified in the instructions. It omits crucial information and fails to explore many relevant aspects of the potential impact of LLMs on the job market.\n",
       "\n",
       "**Clarity**: The article's writing quality is generally clear and easy to understand, but it falls short in terms of conciseness and efficiency. While the information is mostly well-structured and comprehensible, there are instances of unnecessary verbosity and a casual tone that detracts from the overall clarity.\n",
       "\n",
       "The article begins with a clear introduction to the topic, explaining the potential impact of AI on jobs. It effectively uses simple language to describe large language models (LLMs) and their capabilities. This part is well-constructed and easy to follow.\n",
       "\n",
       "However, the article becomes less concise as it progresses. For example, the statement \"It's like having a robot colleague that can do half your work\" is an attempt to simplify the concept, but it adds unnecessary complexity to the explanation. The phrase \"that's pretty surprising, right?\" is another instance of informal language that doesn't contribute to the clarity of the information.\n",
       "\n",
       "The article does a good job of breaking down complex concepts, such as LLM-powered software, into more digestible parts. It explains how these technologies could impact various job roles and industries, which helps in understanding the potential effects of AI on the job market.\n",
       "\n",
       "The conclusion effectively summarizes the main points and suggests areas for further research. This part is well-structured and provides a clear takeaway for the reader.\n",
       "\n",
       "Overall, while the article is generally clear and easy to understand, it could benefit from more concise language and a slightly more formal tone to enhance its clarity and professionalism.\n",
       "\n",
       "**Source_attribution**: The article does not accurately and comprehensively attribute information to reliable sources. The text makes several claims about the impact of AI on the job market, but fails to provide proper attribution to the original sources. For instance, it mentions that \"the study says that people with high-paying jobs might actually be more at risk,\" but does not cite the specific study or provide any details about its findings. Additionally, the article refers to \"some researchers with really long names\" without mentioning the actual authors of the study. This lack of proper sourcing and attribution makes it difficult to verify the accuracy of the information presented. Therefore, the article does not meet the criteria for accurate and comprehensive attribution of information to reliable sources.\n",
       "\n",
       "**Objectivity**: The article presents information about the potential impact of AI on the job market, focusing on large language models (LLMs) and their ability to affect various occupations. However, the article demonstrates a significant bias in its reporting. It primarily presents the perspective that AI will have a substantial impact on jobs, potentially leading to job displacement, especially for high-wage occupations. This viewpoint is presented without adequate representation of alternative perspectives that might argue against the severity of the impact or highlight potential benefits.\n",
       "\n",
       "The language used in the article is somewhat emotionally charged, with phrases like \"robot invasion\" and \"wake up tomorrow and find robots sitting at our desks,\" which could influence the reader's perception. The article also minimizes the complexity of the issue by stating, \"It's hard to know who's right,\" without providing a balanced view of the different opinions and research findings.\n",
       "\n",
       "While the article does mention that further research is needed and that there are differing opinions, it does not provide a fair representation of these alternative viewpoints. The sources cited are limited and do not include credible sources that might offer a more balanced perspective on the potential impact of AI on jobs.\n",
       "\n",
       "Overall, the article lacks the necessary objectivity and balance to be considered unbiased reporting. It presents a one-sided view that heavily favors the perspective of AI having a significant negative impact on jobs, without adequately representing alternative viewpoints or maintaining a neutral tone throughout.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for i in range(len(eval_inputs_batch)):\n",
    "    markdown_content = f\"\\n## Article {i+1}\\n\\n\"\n",
    "    markdown_content += \"| Metric | Score |\\n\"\n",
    "    markdown_content += \"|--------|-------|\\n\"\n",
    "    for metric, results in all_results.items():\n",
    "        score = results[i].score\n",
    "        markdown_content += f\"| {metric} | {score} |\\n\"\n",
    "    \n",
    "    markdown_content += \"\\n### Feedback\\n\\n\"\n",
    "    for metric, results in all_results.items():\n",
    "        feedback = results[i].feedback\n",
    "        markdown_content += f\"**{metric.capitalize()}**: {feedback}\\n\\n\"\n",
    "    \n",
    "    display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
